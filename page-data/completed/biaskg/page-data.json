{"componentChunkName":"component---node-modules-gatsby-theme-garden-src-templates-local-file-js","path":"/completed/biaskg","result":{"data":{"file":{"childMdx":{"body":"var _excluded = [\"components\"];\nfunction _extends() { return _extends = Object.assign ? Object.assign.bind() : function (n) { for (var e = 1; e < arguments.length; e++) { var t = arguments[e]; for (var r in t) ({}).hasOwnProperty.call(t, r) && (n[r] = t[r]); } return n; }, _extends.apply(null, arguments); }\nfunction _objectWithoutProperties(e, t) { if (null == e) return {}; var o, r, i = _objectWithoutPropertiesLoose(e, t); if (Object.getOwnPropertySymbols) { var n = Object.getOwnPropertySymbols(e); for (r = 0; r < n.length; r++) o = n[r], -1 === t.indexOf(o) && {}.propertyIsEnumerable.call(e, o) && (i[o] = e[o]); } return i; }\nfunction _objectWithoutPropertiesLoose(r, e) { if (null == r) return {}; var t = {}; for (var n in r) if ({}.hasOwnProperty.call(r, n)) { if (-1 !== e.indexOf(n)) continue; t[n] = r[n]; } return t; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"BiasKG: Adversarial Knowledge Graphs to Induce Bias in Large Language Models\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"biaskg-adversarial-knowledge-graphs-to-induce-bias-in-large-language-models\"\n  }, \"BiasKG: Adversarial Knowledge Graphs to Induce Bias in Large Language Models\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/VectorInstitute/biaskg\"\n  }, \"Github\")), mdx(\"p\", null, \"Modern large language models (LLMs) have a significant amount of world knowledge, which enables strong performance in commonsense reasoning and knowledge-intensive tasks when harnessed properly. The language model can also learn social biases, which has a significant potential for societal harm. There have been many mitigation strategies proposed for LLM safety, but it is unclear how effective they are for eliminating social biases. \"), mdx(\"p\", null, \"In this work, we propose a new methodology for attacking language models with knowledge graph-augmented generation. We refactor natural language stereotypes into a knowledge graph, and use adversarial attacking strategies to induce biased responses from several open- and closed-source language models. We find our method increases bias in all models, even those trained with safety guardrails. This demonstrates the need for further research in AI safety, and further work in this new adversarial space.\"));\n}\n;\nMDXContent.isMDXComponent = true;","outboundReferences":[],"inboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\nfunction _extends() { return _extends = Object.assign ? Object.assign.bind() : function (n) { for (var e = 1; e < arguments.length; e++) { var t = arguments[e]; for (var r in t) ({}).hasOwnProperty.call(t, r) && (n[r] = t[r]); } return n; }, _extends.apply(null, arguments); }\nfunction _objectWithoutProperties(e, t) { if (null == e) return {}; var o, r, i = _objectWithoutPropertiesLoose(e, t); if (Object.getOwnPropertySymbols) { var n = Object.getOwnPropertySymbols(e); for (r = 0; r < n.length; r++) o = n[r], -1 === t.indexOf(o) && {}.propertyIsEnumerable.call(e, o) && (i[o] = e[o]); } return i; }\nfunction _objectWithoutPropertiesLoose(r, e) { if (null == r) return {}; var t = {}; for (var n in r) if ({}.hasOwnProperty.call(r, n)) { if (-1 !== e.indexOf(n)) continue; t[n] = r[n]; } return t; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Completed Projects\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"completed-projects\"\n  }, \"Completed Projects\"), mdx(\"p\", null, \"Here you can find the repositories and papers for projects I would consider complete-ish. Some pages have post-mortem reflections - what I could have done better, what is left to be explored, etc.\"), mdx(\"h2\", {\n    \"id\": \"interpretability\"\n  }, \"Interpretability\"), mdx(\"p\", null, \"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/prototypes\",\n    \"title\": \"prototypes\"\n  }, \"[[prototypes]]\"), \" - Making citation prediction more easily understood by lawyers with prototype theory, precedents, and legislation\"), mdx(\"h2\", {\n    \"id\": \"datasets\"\n  }, \"Datasets\"), mdx(\"p\", null, \"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/legalhatespeech\",\n    \"title\": \"legalhatespeech\"\n  }, \"[[legalhatespeech]]\"), \" - Grounding the subjectivity of hate speech in 11 definitions from various legal authorities\"), mdx(\"p\", null, \"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/misinformation\",\n    \"title\": \"misinformation\"\n  }, \"[[misinformation]]\"), \" - Grounding the assessment of misinformation in possible legal implications\"), mdx(\"h2\", {\n    \"id\": \"bias\"\n  }, \"Bias\"), mdx(\"p\", null, \"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/biaskg\",\n    \"title\": \"biaskg\"\n  }, \"[[biaskg]]\"), \" - Building a dynamic knowledge graph from natural language for assessing social bias in LLMs\"), mdx(\"h2\", {\n    \"id\": \"test-time-alignment\"\n  }, \"Test-time Alignment\"), mdx(\"p\", null, \"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/sae-pd\",\n    \"title\": \"sae-pd\"\n  }, \"[[sae-pd]]\"), \" - Investigating model steering with Sparse Autoencoders (SAEs) for pluralistic alignment on sparse legal data\"));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"43c4e06e-a3ed-5032-881b-07cea9e40167","fields":{"slug":"/indexes/completed-projects","title":"Completed Projects"}}}]},"fields":{"slug":"/completed/biaskg","title":"BiasKG: Adversarial Knowledge Graphs to Induce Bias in Large Language Models"}}},"pageContext":{"id":"92072389-ab37-5d80-968d-f3417aa39fd8"}},"staticQueryHashes":["2098632890","2221750479","2468095761"]}