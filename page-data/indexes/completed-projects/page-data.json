{"componentChunkName":"component---node-modules-gatsby-theme-garden-src-templates-local-file-js","path":"/indexes/completed-projects","result":{"data":{"file":{"childMdx":{"body":"var _excluded = [\"components\"];\nfunction _extends() { return _extends = Object.assign ? Object.assign.bind() : function (n) { for (var e = 1; e < arguments.length; e++) { var t = arguments[e]; for (var r in t) ({}).hasOwnProperty.call(t, r) && (n[r] = t[r]); } return n; }, _extends.apply(null, arguments); }\nfunction _objectWithoutProperties(e, t) { if (null == e) return {}; var o, r, i = _objectWithoutPropertiesLoose(e, t); if (Object.getOwnPropertySymbols) { var n = Object.getOwnPropertySymbols(e); for (r = 0; r < n.length; r++) o = n[r], -1 === t.indexOf(o) && {}.propertyIsEnumerable.call(e, o) && (i[o] = e[o]); } return i; }\nfunction _objectWithoutPropertiesLoose(r, e) { if (null == r) return {}; var t = {}; for (var n in r) if ({}.hasOwnProperty.call(r, n)) { if (-1 !== e.indexOf(n)) continue; t[n] = r[n]; } return t; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Completed Projects\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"completed-projects\"\n  }, \"Completed Projects\"), mdx(\"p\", null, \"Here you can find the repositories and papers for projects I would consider complete-ish. Some pages have post-mortem reflections - what I could have done better, what is left to be explored, etc.\"), mdx(\"p\", null, \"These are all projects where I was the first author; this means I wrote the entire codebase (except for BiasKG, where I designed the core knowledge graph algorithm and my co-author Ahmed implemented it, and then we ran half of the experiments each) and paper.\"), mdx(\"h2\", {\n    \"id\": \"interpretability\"\n  }, \"Interpretability\"), mdx(\"p\", null, \"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/prototypes\",\n    \"title\": \"prototypes\"\n  }, \"[[prototypes]]\"), \" - Making citation prediction more easily understood by lawyers with prototype theory, precedents, and legislation\"), mdx(\"h2\", {\n    \"id\": \"datasets\"\n  }, \"Datasets\"), mdx(\"p\", null, \"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/legalhatespeech\",\n    \"title\": \"legalhatespeech\"\n  }, \"[[legalhatespeech]]\"), \" - Grounding the subjectivity of hate speech in 11 definitions from various legal authorities\"), mdx(\"p\", null, \"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/misinformation\",\n    \"title\": \"misinformation\"\n  }, \"[[misinformation]]\"), \" - Grounding the assessment of misinformation in possible legal implications\"), mdx(\"h2\", {\n    \"id\": \"bias\"\n  }, \"Bias\"), mdx(\"p\", null, \"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/biaskg\",\n    \"title\": \"biaskg\"\n  }, \"[[biaskg]]\"), \" - Building a dynamic knowledge graph from natural language for assessing social bias in LLMs\"), mdx(\"h2\", {\n    \"id\": \"test-time-alignment\"\n  }, \"Test-time Alignment\"), mdx(\"p\", null, \"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/sae-pd\",\n    \"title\": \"sae-pd\"\n  }, \"[[sae-pd]]\"), \" - Investigating model steering with Sparse Autoencoders (SAEs) for pluralistic alignment on sparse legal data\"));\n}\n;\nMDXContent.isMDXComponent = true;","outboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\nfunction _extends() { return _extends = Object.assign ? Object.assign.bind() : function (n) { for (var e = 1; e < arguments.length; e++) { var t = arguments[e]; for (var r in t) ({}).hasOwnProperty.call(t, r) && (n[r] = t[r]); } return n; }, _extends.apply(null, arguments); }\nfunction _objectWithoutProperties(e, t) { if (null == e) return {}; var o, r, i = _objectWithoutPropertiesLoose(e, t); if (Object.getOwnPropertySymbols) { var n = Object.getOwnPropertySymbols(e); for (r = 0; r < n.length; r++) o = n[r], -1 === t.indexOf(o) && {}.propertyIsEnumerable.call(e, o) && (i[o] = e[o]); } return i; }\nfunction _objectWithoutPropertiesLoose(r, e) { if (null == r) return {}; var t = {}; for (var n in r) if ({}.hasOwnProperty.call(r, n)) { if (-1 !== e.indexOf(n)) continue; t[n] = r[n]; } return t; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Prototype-based Interpretability for Legal Citation Prediction\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"prototype-based-interpretability-for-legal-citation-prediction\"\n  }, \"Prototype-based Interpretability for Legal Citation Prediction\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/chufeiluo/prototype-lcp\"\n  }, \"Github\")), mdx(\"h2\", {\n    \"id\": \"project-description\"\n  }, \"Project Description\"), mdx(\"p\", null, \"Deep learning has made significant progress in the past decade, and demonstrates potential to solve problems with extensive social impact. In high-stakes decision making areas such as law, experts often require interpretability for automatic systems to be utilized in practical settings. \"), mdx(\"p\", null, \"In this work, we attempt to address these requirements applied to the important problem of legal citation prediction (LCP). We design the task with parallels to the thought-process of lawyers, i.e., with reference to both precedents and legislative provisions. After initial experimental results, we refine the target citation predictions with the feedback of legal experts. Additionally, we introduce a prototype architecture to add interpretability, achieving strong performance while adhering to decision parameters used by lawyers. \"), mdx(\"p\", null, \"Our study builds on and leverages the state-of-the-art language processing models for law, while addressing vital considerations for high-stakes tasks with practical societal impact.\"), mdx(\"h2\", {\n    \"id\": \"significance\"\n  }, \"Significance\"), mdx(\"p\", null, \"This project studied:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"How to modify a pre-trained model to have inherent interpretability. \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"How to design tasks and evaluations catered to legal experts\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Tradeoffs between interpretability and abstraction\")), mdx(\"p\", null, \"Many people assume that there is a tradeoff between inherent interpretability and model performance, and a model that's easier to understand loses some of the complexities. This work is both supporting and refuting that; while there is some amount of information lost in the \\\"non-procedural\\\" citations that have more abstract/analogous relationships between each other (e.g. don't have much keyword overlap, etc.), the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"overall system performs better\"), \" after organizing the latent space more clearly.\"), mdx(\"h2\", {\n    \"id\": \"post-mortem\"\n  }, \"Post mortem\"), mdx(\"p\", null, \"I like this paper, still. This was my first paper accepted to a top venue, after a year of being in review (it was first submitted to EMNLP in 2022, accepted to ACL 2023).\"), mdx(\"p\", null, \"I think hindsight is 20-20 - many people complain that reviews are harsh now, but they were honestly just as harsh in 2022, if not harsher. I won't complain about them too much here, but let's just say peer review has never been kind to me. It also feels like another world, honestly. I don't know if the ideas we presented in this paper would be accepted now - it doesn't feel like inherent interpretability is as popular as mechanistic interpretability. It's gotten better recently, but I think that's an aspect of research that burns me out quickly - the feeling that my body of work is no longer interesting to anyone. I think nowadays, I'm more satisfied just pursuing what I find interesting.\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"1fd4ed0c-c082-5607-8d2b-af173815f24b","fields":{"slug":"/completed/prototypes","title":"Prototype-based Interpretability for Legal Citation Prediction"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\nfunction _extends() { return _extends = Object.assign ? Object.assign.bind() : function (n) { for (var e = 1; e < arguments.length; e++) { var t = arguments[e]; for (var r in t) ({}).hasOwnProperty.call(t, r) && (n[r] = t[r]); } return n; }, _extends.apply(null, arguments); }\nfunction _objectWithoutProperties(e, t) { if (null == e) return {}; var o, r, i = _objectWithoutPropertiesLoose(e, t); if (Object.getOwnPropertySymbols) { var n = Object.getOwnPropertySymbols(e); for (r = 0; r < n.length; r++) o = n[r], -1 === t.indexOf(o) && {}.propertyIsEnumerable.call(e, o) && (i[o] = e[o]); } return i; }\nfunction _objectWithoutPropertiesLoose(r, e) { if (null == r) return {}; var t = {}; for (var n in r) if ({}.hasOwnProperty.call(r, n)) { if (-1 !== e.indexOf(n)) continue; t[n] = r[n]; } return t; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Towards legally enforceable hate speech detection for public forums\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"towards-legally-enforceable-hate-speech-detection-for-public-forums\"\n  }, \"Towards legally enforceable hate speech detection for public forums\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/chufeiluo/legalhatespeech\"\n  }, \"Github\")), mdx(\"h2\", {\n    \"id\": \"project-description\"\n  }, \"Project Description\"), mdx(\"p\", null, \"Hate speech causes widespread and deep-seated societal issues. Proper enforcement of hate speech laws is key for protecting groups of people against harmful and discriminatory language. However, determining what constitutes hate speech is a complex task that is highly open to subjective interpretations. Existing works do not align their systems with enforceable definitions of hate speech, which can make their outputs inconsistent with the goals of regulators. \"), mdx(\"p\", null, \"This research introduces a new perspective and task for enforceable hate speech detection centred around legal definitions, and a dataset annotated on violations of eleven possible definitions by legal experts. Given the challenge of identifying clear, legally enforceable instances of hate speech, we augment the dataset with expert-generated samples and an automatically mined challenge set. We experiment with grounding the model decision in these definitions using zero-shot and few-shot prompting. We then report results on several large language models (LLMs). \"), mdx(\"p\", null, \"With this task definition, automatic hate speech detection can be more closely aligned to enforceable laws, and hence assist in more rigorous enforcement of legal protections against harmful speech in public forums.\"), mdx(\"h2\", {\n    \"id\": \"significance\"\n  }, \"Significance\"), mdx(\"p\", null, \"This project studied:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"How to ground evaluations to be meaningful to another, specialized audience\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"It was one of the first to benchmark LLMs - most of the experiments were completed January 2023 - against existing prompt tuning methods\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"What is the source of ambiguity in other hate speech datasets\")), mdx(\"p\", null, \"The paper also studied how to use self-training with silver labels to improve performance to match GPT-4 but with a much smaller model (RoBERTa-Large). This was only on a 3-way classification task and, as found in follow-up studies (\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/sae-pd\",\n    \"title\": \"sae-pd\"\n  }, \"[[sae-pd]]\"), \"), there are some lexical features that allow LLMs to learn this classification label really well with few-shot prompting. \"), mdx(\"h2\", {\n    \"id\": \"post-mortem\"\n  }, \"Post mortem\"), mdx(\"p\", null, \"I still like this project. I think I'm still proud of it. I don't think the reasoning analysis is in-depth enough by today's standards, and my thoughts on model training vs. prompting flip-flop every so often, but it's been a while since I've had a paper compare model training to prompting. \"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"af4ce0a7-005b-5368-8770-5764a771d61e","fields":{"slug":"/completed/legalhatespeech","title":"Towards legally enforceable hate speech detection for public forums"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\nfunction _extends() { return _extends = Object.assign ? Object.assign.bind() : function (n) { for (var e = 1; e < arguments.length; e++) { var t = arguments[e]; for (var r in t) ({}).hasOwnProperty.call(t, r) && (n[r] = t[r]); } return n; }, _extends.apply(null, arguments); }\nfunction _objectWithoutProperties(e, t) { if (null == e) return {}; var o, r, i = _objectWithoutPropertiesLoose(e, t); if (Object.getOwnPropertySymbols) { var n = Object.getOwnPropertySymbols(e); for (r = 0; r < n.length; r++) o = n[r], -1 === t.indexOf(o) && {}.propertyIsEnumerable.call(e, o) && (i[o] = e[o]); } return i; }\nfunction _objectWithoutPropertiesLoose(r, e) { if (null == r) return {}; var t = {}; for (var n in r) if ({}.hasOwnProperty.call(r, n)) { if (-1 !== e.indexOf(n)) continue; t[n] = r[n]; } return t; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Misinformation with legal consequences (MisLC): A new task towards harnessing societal harm of misinformation\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"misinformation-with-legal-consequences-mislc-a-new-task-towards-harnessing-societal-harm-of-misinformation\"\n  }, \"Misinformation with legal consequences (MisLC): A new task towards harnessing societal harm of misinformation\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/chufeiluo/mislc\"\n  }, \"Github\")), mdx(\"h2\", {\n    \"id\": \"project-description\"\n  }, \"Project description\"), mdx(\"p\", null, \"Misinformation, defined as false or inaccurate information, can result in significant societal harm when it is spread with malicious or even innocuous intent. The rapid online information exchange necessitates advanced detection mechanisms to mitigate misinformationinduced harm. Existing research, however, has predominantly focused on assessing veracity, overlooking the legal implications and social consequences of misinformation. \"), mdx(\"p\", null, \"In this work, we take a novel angle to consolidate the definition of misinformation detection using legal issues as a measurement of societal ramifications, aiming to bring interdisciplinary efforts to tackle misinformation and its consequence. \"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"We introduce a new task: Misinformation with Legal Consequence (MisLC), which leverages definitions from a wide range of legal domains covering 4 broader legal topics and 11 fine-grained legal issues, including hate speech, election laws, and privacy regulations. \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"For this task, we advocate a two-step dataset curation approach that utilizes crowd-sourced checkworthiness and expert evaluations of misinformation. \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"We provide insights about the MisLC task through empirical evidence, from the problem definition to experiments and expert involvement. \")), mdx(\"p\", null, \"While the latest large language models and retrieval-augmented generation are effective baselines for the task, we find they are still far from replicating expert performance.\"), mdx(\"h2\", {\n    \"id\": \"significance\"\n  }, \"Significance\"), mdx(\"p\", null, \"This project studied:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"How to effectively cover more data in annotations while budgeting between general and specialized annotators\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"How to practically apply the state-of-the-art in RAG to real-world data\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"How to ground evaluations to be meaningful to another, specialized audience\")), mdx(\"h2\", {\n    \"id\": \"post-mortem\"\n  }, \"Post-mortem\"), mdx(\"p\", null, \"Recently, I read other researchers discussing what is research that is done for the sake of getting published, and what is research that is meaningful. There are an obviously infinite number of projects we can pursue in one lifetime, but a finite amount of time, so it is important to choose the deeper explorations carefully. In this case, the misinformation project was just trying to transfer some of my ideas from \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/legalhatespeech\",\n    \"title\": \"legalhatespeech\"\n  }, \"[[legalhatespeech]]\"), \" on a new task, but it did not synergize as well.\"), mdx(\"p\", null, \"For one, the task of verifying misinformation is more complex - in some ways it is like deep research, where you recursively identify claims and then search the internet trying to verify them. Compared to hate speech, which can often be judged on a single social media post, misinformation is more multi-hop and leaves more room for ambiguity. The key is \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"context\"), \". While the legal hate speech dataset isolated samples that were completely, unambiguously hateful, this dataset contained fragmented posts that were taken out of the original conversation.\"), mdx(\"p\", null, \"For another, hate speech was just easier because there were more works published. It was easy to identify the gap that my research filled, and it was easier to justify why it was important without asking people to understand the value of my vision. While I did get to present my work at EMNLP, and some kind people found my work interesting, it feels like most people dismissed this work. I understand why - I've reviewed a fair share of papers that try to use social impact to cover for the fact that their experimental setup was weak. \"), mdx(\"p\", null, \"This paper also did not do any training, while hate speech used some self-training, etc. so the results weren't very comprehensive - it felt like it was trying to capitalize on RAG, which was trending at the time. It also felt kind of like clickbait - just another paper reviewing the shortcomings of current LLMs, LLMs are still far from solving problems, etc. etc.\"), mdx(\"p\", null, \"I've come to realize that a lot of unoriginal thought comes from focusing too much on \\\"common\\\" knowledge, and defining your work as supporting or subverting what is widely accepted. This is okay when you are trying to present your work at a conference, but I've realized that this line of thinking during actual paper writing just makes extremely weak work. It obfuscates the ideas that were actually interesting (in my opinion), like the two-step pipeline of cheaper to more expensive annotation.\"), mdx(\"p\", null, \"Also, I was just really burnt out at the time and I didn't do as much as I wanted for this paper. Like I previously mentioned, I didn't put model training into this paper - I actually did attempt tuning a 7b model with LoRA, but I started too late. I wanted to compare human to LLM-generated annotations. I wanted to do a more careful design of the RAG pipeline.\"), mdx(\"p\", null, \"Of course, all of these feelings are normal for a project after it's done - this one is just memorable because it felt like a culmination of my burnout. Maybe I will do all of the above for my thesis, or for another paper. Maybe I will leave this project untouched for the rest of eternity. Either way, I think the regrets I have over this project have carried over into subsequent work.\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"ef338408-2e8f-54f6-a22f-4759ce21a40e","fields":{"slug":"/completed/misinformation","title":"Misinformation with legal consequences (MisLC): A new task towards harnessing societal harm of misinformation"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\nfunction _extends() { return _extends = Object.assign ? Object.assign.bind() : function (n) { for (var e = 1; e < arguments.length; e++) { var t = arguments[e]; for (var r in t) ({}).hasOwnProperty.call(t, r) && (n[r] = t[r]); } return n; }, _extends.apply(null, arguments); }\nfunction _objectWithoutProperties(e, t) { if (null == e) return {}; var o, r, i = _objectWithoutPropertiesLoose(e, t); if (Object.getOwnPropertySymbols) { var n = Object.getOwnPropertySymbols(e); for (r = 0; r < n.length; r++) o = n[r], -1 === t.indexOf(o) && {}.propertyIsEnumerable.call(e, o) && (i[o] = e[o]); } return i; }\nfunction _objectWithoutPropertiesLoose(r, e) { if (null == r) return {}; var t = {}; for (var n in r) if ({}.hasOwnProperty.call(r, n)) { if (-1 !== e.indexOf(n)) continue; t[n] = r[n]; } return t; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"BiasKG: Adversarial Knowledge Graphs to Induce Bias in Large Language Models\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"biaskg-adversarial-knowledge-graphs-to-induce-bias-in-large-language-models\"\n  }, \"BiasKG: Adversarial Knowledge Graphs to Induce Bias in Large Language Models\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/VectorInstitute/biaskg\"\n  }, \"Github\")), mdx(\"p\", null, \"Modern large language models (LLMs) have a significant amount of world knowledge, which enables strong performance in commonsense reasoning and knowledge-intensive tasks when harnessed properly. The language model can also learn social biases, which has a significant potential for societal harm. There have been many mitigation strategies proposed for LLM safety, but it is unclear how effective they are for eliminating social biases. \"), mdx(\"p\", null, \"In this work, we propose a new methodology for attacking language models with knowledge graph-augmented generation. We refactor natural language stereotypes into a knowledge graph, and use adversarial attacking strategies to induce biased responses from several open- and closed-source language models. We find our method increases bias in all models, even those trained with safety guardrails. This demonstrates the need for further research in AI safety, and further work in this new adversarial space.\"), mdx(\"h2\", {\n    \"id\": \"significance\"\n  }, \"Significance\"), mdx(\"p\", null, \"This project studied:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"How to create a knowledge graph from natural language phrases\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"How to attack language models in a thorough, automated way\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"How social bias can change depending on the input prompt\")), mdx(\"h2\", {\n    \"id\": \"post-mortem\"\n  }, \"Post mortem\"), mdx(\"p\", null, \"I like the knowledge graph portion of this project, but I think the application to red-teaming is somewhat impractical now that the field is more mature. It was a good first attempt in a relatively new space, but red-teaming LLMs seems to be a fool's errand. There will always be a corner that is untested, and unlike traditional software, the cost of patching a hole is more than modifying some code - you would need to retrain the model, probably quite significantly.\"), mdx(\"p\", null, \"In general, this project made me realize poorly trained LLMs still have all of the flaws of their predecessors. Minor changes in the input can result in significant changes to the output. Also, the temperature and other sampling parameters could change the result significantly. Recent models have removed temperature completely, probably for this reason. I realized that publishing on API-based models was also a fool's errand. We performed experiments with the same model (GPT-3.5) several months apart and received completely different results.\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"92072389-ab37-5d80-968d-f3417aa39fd8","fields":{"slug":"/completed/biaskg","title":"BiasKG: Adversarial Knowledge Graphs to Induce Bias in Large Language Models"}}},{"__typename":"Mdx","body":"var _excluded = [\"components\"];\nfunction _extends() { return _extends = Object.assign ? Object.assign.bind() : function (n) { for (var e = 1; e < arguments.length; e++) { var t = arguments[e]; for (var r in t) ({}).hasOwnProperty.call(t, r) && (n[r] = t[r]); } return n; }, _extends.apply(null, arguments); }\nfunction _objectWithoutProperties(e, t) { if (null == e) return {}; var o, r, i = _objectWithoutPropertiesLoose(e, t); if (Object.getOwnPropertySymbols) { var n = Object.getOwnPropertySymbols(e); for (r = 0; r < n.length; r++) o = n[r], -1 === t.indexOf(o) && {}.propertyIsEnumerable.call(e, o) && (i[o] = e[o]); } return i; }\nfunction _objectWithoutPropertiesLoose(r, e) { if (null == r) return {}; var t = {}; for (var n in r) if ({}.hasOwnProperty.call(r, n)) { if (-1 !== e.indexOf(n)) continue; t[n] = r[n]; } return t; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Towards Low-Resource Alignment to Diverse Perspectives with Sparse Feedback\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"towards-low-resource-alignment-to-diverse-perspectives-with-sparse-feedback\"\n  }, \"Towards Low-Resource Alignment to Diverse Perspectives with Sparse Feedback\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/chufeiluo/SAE-PD\"\n  }, \"Github\")), mdx(\"p\", null, \"As language models have a greater impact on society, it is important to ensure they are aligned to a diverse range of perspectives and are able to reflect nuance in human values. However, the most popular training paradigms for modern language models often assume there is one optimal answer for every query, leading to generic responses and poor alignment. \"), mdx(\"p\", null, \"In this work, we aim to enhance pluralistic alignment of language models in a low-resource setting with two methods: pluralistic decoding and model steering. We empirically demonstrate that model steering offers consistent improvement over zero-shot and few-shot baselines with only 50 annotated samples. Our proposed methods decrease false positives in several high-stakes tasks such as hate speech detection and misinformation detection, and improves the distributional alignment to human values from different demographics. \"), mdx(\"p\", null, \"We hope our work highlights the importance of diversity and how language models can be adapted to consider nuanced perspectives.\"), mdx(\"h2\", {\n    \"id\": \"significance\"\n  }, \"Significance\"), mdx(\"p\", null, \"This project studies:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"How to do model alignment without model training\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Model steering on some abstract attribute (\\\"feedback\\\") instead of something concrete (e.g. hallucinations)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"How to combine multiple steering vectors at the decoding stage (works with or without model steering)\")), mdx(\"h2\", {\n    \"id\": \"post-mortem\"\n  }, \"Post-mortem?\"), mdx(\"p\", null, \"To be honest, I'm not really satisfied with this project to the point that I hesitate to call this a post-mortem. I'm not leaving this project here, to be sure. I think the idea itself could be refined a little more. At its core I'm trying to ask: how can I use expert feedback efficiently? Can I emulate the behaviour of a model that has seen expert feedback, without needing an expert to give feedback on every single sample? I'm not sure how much that came across\"), mdx(\"p\", null, \"I read a paper recently (\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2406.02543\"\n  }, \"To believe or not to believe your LLM\"), \") and it gave me new ideas for this paper. Basically, for any predicted token, you can measure the LLM's certainty in its prediction based on the change in probability over repetitions in the input context. If the probability fluctuates/drops when there are alternate answers in the context, this implies model is more easily influenced into changing its answer, so it's less sure. A very intuitive idea, and it works empirically.\"), mdx(\"p\", null, \"In the context of my pluralistic decoding strategy, Pluralistic decoding, we perform 3 steps:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Take the difference in logit distribution between the base + steered logit\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Measuring the entropy of the difference\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Weighing the difference by the magnitude of entropy, add the displacement back to the base logit\")), mdx(\"p\", null, \"Intuitively, the more the steered logit changed compared to the base, the more it would influence the final prediction logit. I was thinking this would reduce redundant information (i.e. we care about the logits that change significantly compared to the base, and we don't want them to get lost in an average of 6 other logits) but it also, in hindsight, \\\"flattens\\\" the prediction distribution when language models are more easily influenced. It's a kind of calibration in a way - if the model has a 0.9 chance of predicting \\\"Yes\\\" in the base vector, but a 0.9 chance of predicting \\\"No\\\" in one steering direction and a 0.9 chance of predicting \\\"Unclear\\\" in another steering direction, that should flatten out the distribution over all 3 choices. This reduces overconfidence, or places where a model was maybe too certain in the base instance. Maybe there is something there in reducing or detecting hallucinations, but for cheaper than the original paper?\"), mdx(\"p\", null, \"This paper had some interesting results, but I think it's a bit shallow.. I want to revisit this project if I get the time\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"aliases":[]},"parent":{"__typename":"File","id":"5a4d9fbb-e68a-5c47-bdb2-4b374aa740dd","fields":{"slug":"/completed/sae-pd","title":"Towards Low-Resource Alignment to Diverse Perspectives with Sparse Feedback"}}}],"inboundReferences":[{"__typename":"Mdx","body":"var _excluded = [\"components\"];\nfunction _extends() { return _extends = Object.assign ? Object.assign.bind() : function (n) { for (var e = 1; e < arguments.length; e++) { var t = arguments[e]; for (var r in t) ({}).hasOwnProperty.call(t, r) && (n[r] = t[r]); } return n; }, _extends.apply(null, arguments); }\nfunction _objectWithoutProperties(e, t) { if (null == e) return {}; var o, r, i = _objectWithoutPropertiesLoose(e, t); if (Object.getOwnPropertySymbols) { var n = Object.getOwnPropertySymbols(e); for (r = 0; r < n.length; r++) o = n[r], -1 === t.indexOf(o) && {}.propertyIsEnumerable.call(e, o) && (i[o] = e[o]); } return i; }\nfunction _objectWithoutPropertiesLoose(r, e) { if (null == r) return {}; var t = {}; for (var n in r) if ({}.hasOwnProperty.call(r, n)) { if (-1 !== e.indexOf(n)) continue; t[n] = r[n]; } return t; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Hello!\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"hello\"\n  }, \"Hello!\"), mdx(\"p\", null, \"Welcome!\"), mdx(\"h2\", {\n    \"id\": \"main-starting-points\"\n  }, \"Main starting points\"), mdx(\"p\", null, \"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/Completed-Projects\",\n    \"title\": \"Completed Projects\"\n  }, \"[[Completed Projects]]\"), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/Ongoing-Projects\",\n    \"title\": \"Ongoing Projects\"\n  }, \"[[Ongoing Projects]]\"), \"\"), mdx(\"p\", null, \"Link to another note \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/Hi\",\n    \"title\": \"Hi\"\n  }, \"[[Hi]]\"), \"\"));\n}\n;\nMDXContent.isMDXComponent = true;","parent":{"__typename":"File","id":"123fb877-0ab5-55da-972e-ff1a47896274","fields":{"slug":"/hello","title":"Hello!"}}}]},"fields":{"slug":"/indexes/completed-projects","title":"Completed Projects"}}},"pageContext":{"id":"43c4e06e-a3ed-5032-881b-07cea9e40167"}},"staticQueryHashes":["2098632890","2221750479","2468095761"]}